---
layout: post
title: Spark监控管理
tag: Spark
---

### Web界面
　　Spark UI监控管理界面的入口：http://<master节点地址>:8080

　　Spark框架会给每一个SparkContext启动一个默认的Web界面，默认端口是4040，该界面显示了关于程序运行情况的信息，包括：
* Stages和Task列表
* RDD的信息统计和内存情况
* 环境变量
* 正在运行Executors的相关信息

　　访问地址：http://<driver节点地址>:4040

　　如果同时运行多个SparkContext，则端口会顺延到4041、4042...

　　默认情况下，这些信息只能在程序运行期间被访问。程序运行结束后仍要访问的话，需要配置`$SPARK_HOME/conf/spark-default.conf`中的`spark.eventLog.enabled`为`true`。然后Spark会将Web信息编码并以文件的形式持久化。

### Spark UI 历史监控
　　官方说明：http://spark.apache.org/docs/latest/monitoring.html

　　通过SparkUI监控日志，能更直观的查询任务情况，如内存占用、响应时间、完成情况。

　　spark-sever：当Spark运行在集群，如YARN或者Mesos中，spark-history-sever仍然可以满足我们的需求。

　　默认配置的方式启动spark-history-server:
```
    cd $SPARK_HOME/sbin
    ./start-history-server.sh
```
　　在启用spark-history-server，需要指定日志信息保存的目录位置，并且这个目录已经被创建，否运行./start-history-server.sh的时候会报错。

　　日志信息的保存目录通过`$SPARK_HOME/conf/spark-default.conf`中的`spark.history.fs.logDirectory`参数来指定。也可以通过脚本传参来指定，例如`./start-history-server.sh hdfs://localhost:9000/sparkLogs`

　　如果要压缩记录Spark事件，通过`$SPARK_HOME/conf/spark-default.conf`中的`spark.eventLog.compress`为`true`，前提是`spark.eventLog.enabled`也为`true`。`spark.eventLog.compress`默认值是`snappy`

　　spark-history-server的默认端口是18080，启动完成之后，通过地址：http://localhost:18080访问

　　配置在`spark-env.sh`中的参数如下：
```
SPARK_DAEMON_MEMORY	# Memory to allocate to the history server (default: 1g).
SPARK_DAEMON_JAVA_OPTS	# JVM options for the history server (default: none).
SPARK_PUBLIC_DNS	# The public address for the history server. If this is not set, links to application history may use the internal address of the server, resulting in broken links (default: none).
SPARK_HISTORY_OPTS	# spark.history.* configuration options for the history server (default: none).
```
　　例如：
```
export SPARK_HISTROY_OPTS="-Dspark.history.ui.port=666 -Dspark.history.retainedApplications=3 -Dspark.histroy.fs.logDirectory=hdfs://localhost:9000/sparkLogs"
```
　　spark.history.*中的属性都可以配置在`spark-env.sh`中的`SPARK_HISTORY_OPTS`中，也可以直接配置在`spark-default.conf`中。