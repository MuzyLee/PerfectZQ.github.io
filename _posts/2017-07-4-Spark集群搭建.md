---
layout: post
title: Spark 集群搭建
tag: Spark
---

### Standalone模式部署
1. 去官网：http://spark.apache.org/downloads.html下载对应版本的Spark，解压。
2. 主节点设置：

    1) `cd $SPARK_HOME/conf`
    
    2) `cp spark-env.sh.template spark-env.sh`
    
    3) `vi spark-env.sh`
    ```
    export SPARK_MASTER_IP=s121202 # 前提是在hosts文件中指定了域名
    export JAVA_HOME=/usr/java/jdk1.8.0_121
    ```
    
    4) `vi ~/.bash_profile`
    ```
    SPARK_HOME=/opt/neu/spark-2.1.1-bin-hadoop2.6
    export SPARK_HOME
    PATH=$PATH:$SPARK_HOME/bin:$SPARK_HOME/sbin
    export PATH
    ```
    5) `spark-shell` ，版本验证
3. 将从节点配置到slaves文件中
```
vi $SPARK_HOME/conf/slaves
# 添加下面的从节点
s121203
s121204
s121205
s121206
s121207
```
4. 配置Master无密钥登陆Slaves节点
```
    # 如果系统没有ssh，可能需要安装
    yum -y install openssh-server
    # 生成公钥
    ssh-keygen -t rsa -P "" 
    # authorized_keys文件的权限为644
    cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys
    # 刷新
    sudo /etc/init.d/ssh reload
    # ssh验证配置
    ssh localhost
    # 将Master节点的authorized_keys发送到所有的Slaves节点，并登陆验证
    scp ~/.ssh/authorized_keys neu@s121203:~/.ssh/
```
5. 将spark项目完整的发送到子节点
```
scp -rp /opt/neu/spark-2.1.1-bin-hadoop2.6 neu@s121203:/opt/neu/
```
6. 启动集群
```
$SPARK_HOME/./sbin/start-all.sh
```
7. 查看启动情况
```
jps # 主节点可以看到Master和worker两个进程，从节点可以看到worker一个进程
```